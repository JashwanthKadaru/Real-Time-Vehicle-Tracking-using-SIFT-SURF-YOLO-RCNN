{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in c:\\users\\91939\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (8.1.29)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in c:\\users\\91939\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ultralytics) (3.5.3)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in c:\\users\\91939\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ultralytics) (4.9.0.80)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\users\\91939\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ultralytics) (9.2.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\91939\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ultralytics) (6.0.1)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\91939\\appdata\\roaming\\python\\python310\\site-packages (from ultralytics) (2.31.0)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\91939\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ultralytics) (1.11.2)\n",
      "Requirement already satisfied: torch>=1.8.0 in c:\\users\\91939\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ultralytics) (2.2.1)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in c:\\users\\91939\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ultralytics) (0.17.1)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\users\\91939\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ultralytics) (4.66.2)\n",
      "Requirement already satisfied: psutil in c:\\users\\91939\\appdata\\roaming\\python\\python310\\site-packages (from ultralytics) (5.9.5)\n",
      "Requirement already satisfied: py-cpuinfo in c:\\users\\91939\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: thop>=0.1.1 in c:\\users\\91939\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ultralytics) (0.1.1.post2209072238)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\91939\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ultralytics) (2.0.3)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in c:\\users\\91939\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ultralytics) (0.13.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\91939\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\91939\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.37.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\91939\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\91939\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\91939\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (24.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\91939\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\91939\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\91939\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\91939\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\91939\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\91939\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\91939\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.23.0->ultralytics) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\91939\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2023.7.22)\n",
      "Requirement already satisfied: filelock in c:\\users\\91939\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\91939\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.8.0->ultralytics) (4.10.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\91939\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.8.0->ultralytics) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\91939\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\91939\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\91939\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2023.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\91939\\appdata\\roaming\\python\\python310\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\91939\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\91939\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\91939\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: deep-sort-realtime in c:\\users\\91939\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.3.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\91939\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from deep-sort-realtime) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\91939\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from deep-sort-realtime) (1.11.2)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\91939\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from deep-sort-realtime) (4.9.0.80)\n",
      "Requirement already satisfied: torch in c:\\users\\91939\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.2.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\91939\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.17.1)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\91939\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.2.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\91939\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\91939\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (4.10.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\91939\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\91939\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\91939\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\91939\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (2023.4.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\91939\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\91939\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision) (9.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\91939\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\91939\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\91939\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.9.0.80)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\91939\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from opencv-python) (1.26.4)\n",
      "Requirement already satisfied: Cython in c:\\users\\91939\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.0.9)\n"
     ]
    }
   ],
   "source": [
    "# to use YOLOv8\n",
    "! pip install ultralytics\n",
    "! pip install deep-sort-realtime\n",
    "\n",
    "# needed libraries\n",
    "! pip install torch torchvision torchaudio\n",
    "! pip install opencv-python\n",
    "! pip install Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    SORT: A Simple, Online and Realtime Tracker\n",
    "    Copyright (C) 2016-2020 Alex Bewley alex@bewley.ai\n",
    "\n",
    "    This program is free software: you can redistribute it and/or modify\n",
    "    it under the terms of the GNU General Public License as published by\n",
    "    the Free Software Foundation, either version 3 of the License, or\n",
    "    (at your option) any later version.\n",
    "\n",
    "    This program is distributed in the hope that it will be useful,\n",
    "    but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "    GNU General Public License for more details.\n",
    "\n",
    "    You should have received a copy of the GNU General Public License\n",
    "    along with this program.  If not, see <http://www.gnu.org/licenses/>.\n",
    "\"\"\"\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from skimage import io\n",
    "\n",
    "import glob\n",
    "import time\n",
    "import argparse\n",
    "from filterpy.kalman import KalmanFilter\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "\n",
    "def linear_assignment(cost_matrix):\n",
    "  try:\n",
    "    import lap\n",
    "    _, x, y = lap.lapjv(cost_matrix, extend_cost=True)\n",
    "    return np.array([[y[i],i] for i in x if i >= 0]) #\n",
    "  except ImportError:\n",
    "    from scipy.optimize import linear_sum_assignment\n",
    "    x, y = linear_sum_assignment(cost_matrix)\n",
    "    return np.array(list(zip(x, y)))\n",
    "\n",
    "\n",
    "def iou_batch(bb_test, bb_gt):\n",
    "  \"\"\"\n",
    "  From SORT: Computes IOU between two bboxes in the form [x1,y1,x2,y2]\n",
    "  \"\"\"\n",
    "  bb_gt = np.expand_dims(bb_gt, 0)\n",
    "  bb_test = np.expand_dims(bb_test, 1)\n",
    "  \n",
    "  xx1 = np.maximum(bb_test[..., 0], bb_gt[..., 0])\n",
    "  yy1 = np.maximum(bb_test[..., 1], bb_gt[..., 1])\n",
    "  xx2 = np.minimum(bb_test[..., 2], bb_gt[..., 2])\n",
    "  yy2 = np.minimum(bb_test[..., 3], bb_gt[..., 3])\n",
    "  w = np.maximum(0., xx2 - xx1)\n",
    "  h = np.maximum(0., yy2 - yy1)\n",
    "  wh = w * h\n",
    "  o = wh / ((bb_test[..., 2] - bb_test[..., 0]) * (bb_test[..., 3] - bb_test[..., 1])                                      \n",
    "    + (bb_gt[..., 2] - bb_gt[..., 0]) * (bb_gt[..., 3] - bb_gt[..., 1]) - wh)                                              \n",
    "  return(o)  \n",
    "\n",
    "\n",
    "def convert_bbox_to_z(bbox):\n",
    "  \"\"\"\n",
    "  Takes a bounding box in the form [x1,y1,x2,y2] and returns z in the form\n",
    "    [x,y,s,r] where x,y is the centre of the box and s is the scale/area and r is\n",
    "    the aspect ratio\n",
    "  \"\"\"\n",
    "  w = bbox[2] - bbox[0]\n",
    "  h = bbox[3] - bbox[1]\n",
    "  x = bbox[0] + w/2.\n",
    "  y = bbox[1] + h/2.\n",
    "  s = w * h    #scale is just area\n",
    "  r = w / float(h)\n",
    "  return np.array([x, y, s, r]).reshape((4, 1))\n",
    "\n",
    "\n",
    "def convert_x_to_bbox(x,score=None):\n",
    "  \"\"\"\n",
    "  Takes a bounding box in the centre form [x,y,s,r] and returns it in the form\n",
    "    [x1,y1,x2,y2] where x1,y1 is the top left and x2,y2 is the bottom right\n",
    "  \"\"\"\n",
    "  w = np.sqrt(x[2] * x[3])\n",
    "  h = x[2] / w\n",
    "  if(score==None):\n",
    "    return np.array([x[0]-w/2.,x[1]-h/2.,x[0]+w/2.,x[1]+h/2.]).reshape((1,4))\n",
    "  else:\n",
    "    return np.array([x[0]-w/2.,x[1]-h/2.,x[0]+w/2.,x[1]+h/2.,score]).reshape((1,5))\n",
    "\n",
    "\n",
    "class KalmanBoxTracker(object):\n",
    "  \"\"\"\n",
    "  This class represents the internal state of individual tracked objects observed as bbox.\n",
    "  \"\"\"\n",
    "  count = 0\n",
    "  def __init__(self,bbox):\n",
    "    \"\"\"\n",
    "    Initialises a tracker using initial bounding box.\n",
    "    \"\"\"\n",
    "    #define constant velocity model\n",
    "    self.kf = KalmanFilter(dim_x=7, dim_z=4) \n",
    "    self.kf.F = np.array([[1,0,0,0,1,0,0],[0,1,0,0,0,1,0],[0,0,1,0,0,0,1],[0,0,0,1,0,0,0],  [0,0,0,0,1,0,0],[0,0,0,0,0,1,0],[0,0,0,0,0,0,1]])\n",
    "    self.kf.H = np.array([[1,0,0,0,0,0,0],[0,1,0,0,0,0,0],[0,0,1,0,0,0,0],[0,0,0,1,0,0,0]])\n",
    "\n",
    "    self.kf.R[2:,2:] *= 10.\n",
    "    self.kf.P[4:,4:] *= 1000. #give high uncertainty to the unobservable initial velocities\n",
    "    self.kf.P *= 10.\n",
    "    self.kf.Q[-1,-1] *= 0.01\n",
    "    self.kf.Q[4:,4:] *= 0.01\n",
    "\n",
    "    self.kf.x[:4] = convert_bbox_to_z(bbox)\n",
    "    self.time_since_update = 0\n",
    "    self.id = KalmanBoxTracker.count\n",
    "    KalmanBoxTracker.count += 1\n",
    "    self.history = []\n",
    "    self.hits = 0\n",
    "    self.hit_streak = 0\n",
    "    self.age = 0\n",
    "\n",
    "  def update(self,bbox):\n",
    "    \"\"\"\n",
    "    Updates the state vector with observed bbox.\n",
    "    \"\"\"\n",
    "    self.time_since_update = 0\n",
    "    self.history = []\n",
    "    self.hits += 1\n",
    "    self.hit_streak += 1\n",
    "    self.kf.update(convert_bbox_to_z(bbox))\n",
    "\n",
    "  def predict(self):\n",
    "    \"\"\"\n",
    "    Advances the state vector and returns the predicted bounding box estimate.\n",
    "    \"\"\"\n",
    "    if((self.kf.x[6]+self.kf.x[2])<=0):\n",
    "      self.kf.x[6] *= 0.0\n",
    "    self.kf.predict()\n",
    "    self.age += 1\n",
    "    if(self.time_since_update>0):\n",
    "      self.hit_streak = 0\n",
    "    self.time_since_update += 1\n",
    "    self.history.append(convert_x_to_bbox(self.kf.x))\n",
    "    return self.history[-1]\n",
    "\n",
    "  def get_state(self):\n",
    "    \"\"\"\n",
    "    Returns the current bounding box estimate.\n",
    "    \"\"\"\n",
    "    return convert_x_to_bbox(self.kf.x)\n",
    "\n",
    "\n",
    "def associate_detections_to_trackers(detections,trackers,iou_threshold = 0.3):\n",
    "  \"\"\"\n",
    "  Assigns detections to tracked object (both represented as bounding boxes)\n",
    "\n",
    "  Returns 3 lists of matches, unmatched_detections and unmatched_trackers\n",
    "  \"\"\"\n",
    "  if(len(trackers)==0):\n",
    "    return np.empty((0,2),dtype=int), np.arange(len(detections)), np.empty((0,5),dtype=int)\n",
    "\n",
    "  iou_matrix = iou_batch(detections, trackers)\n",
    "\n",
    "  if min(iou_matrix.shape) > 0:\n",
    "    a = (iou_matrix > iou_threshold).astype(np.int32)\n",
    "    if a.sum(1).max() == 1 and a.sum(0).max() == 1:\n",
    "        matched_indices = np.stack(np.where(a), axis=1)\n",
    "    else:\n",
    "      matched_indices = linear_assignment(-iou_matrix)\n",
    "  else:\n",
    "    matched_indices = np.empty(shape=(0,2))\n",
    "\n",
    "  unmatched_detections = []\n",
    "  for d, det in enumerate(detections):\n",
    "    if(d not in matched_indices[:,0]):\n",
    "      unmatched_detections.append(d)\n",
    "  unmatched_trackers = []\n",
    "  for t, trk in enumerate(trackers):\n",
    "    if(t not in matched_indices[:,1]):\n",
    "      unmatched_trackers.append(t)\n",
    "\n",
    "  #filter out matched with low IOU\n",
    "  matches = []\n",
    "  for m in matched_indices:\n",
    "    if(iou_matrix[m[0], m[1]]<iou_threshold):\n",
    "      unmatched_detections.append(m[0])\n",
    "      unmatched_trackers.append(m[1])\n",
    "    else:\n",
    "      matches.append(m.reshape(1,2))\n",
    "  if(len(matches)==0):\n",
    "    matches = np.empty((0,2),dtype=int)\n",
    "  else:\n",
    "    matches = np.concatenate(matches,axis=0)\n",
    "\n",
    "  return matches, np.array(unmatched_detections), np.array(unmatched_trackers)\n",
    "\n",
    "\n",
    "class Sort(object):\n",
    "  def __init__(self, max_age=1, min_hits=3, iou_threshold=0.3):\n",
    "    \"\"\"\n",
    "    Sets key parameters for SORT\n",
    "    \"\"\"\n",
    "    self.max_age = max_age\n",
    "    self.min_hits = min_hits\n",
    "    self.iou_threshold = iou_threshold\n",
    "    self.trackers = []\n",
    "    self.frame_count = 0\n",
    "\n",
    "  def update(self, dets=np.empty((0, 5))):\n",
    "    \"\"\"\n",
    "    Params:\n",
    "      dets - a numpy array of detections in the format [[x1,y1,x2,y2,score],[x1,y1,x2,y2,score],...]\n",
    "    Requires: this method must be called once for each frame even with empty detections (use np.empty((0, 5)) for frames without detections).\n",
    "    Returns the a similar array, where the last column is the object ID.\n",
    "\n",
    "    NOTE: The number of objects returned may differ from the number of detections provided.\n",
    "    \"\"\"\n",
    "    self.frame_count += 1\n",
    "    # get predicted locations from existing trackers.\n",
    "    trks = np.zeros((len(self.trackers), 5))\n",
    "    to_del = []\n",
    "    ret = []\n",
    "    for t, trk in enumerate(trks):\n",
    "      pos = self.trackers[t].predict()[0]\n",
    "      trk[:] = [pos[0], pos[1], pos[2], pos[3], 0]\n",
    "      if np.any(np.isnan(pos)):\n",
    "        to_del.append(t)\n",
    "    trks = np.ma.compress_rows(np.ma.masked_invalid(trks))\n",
    "    for t in reversed(to_del):\n",
    "      self.trackers.pop(t)\n",
    "    matched, unmatched_dets, unmatched_trks = associate_detections_to_trackers(dets,trks, self.iou_threshold)\n",
    "\n",
    "    # update matched trackers with assigned detections\n",
    "    for m in matched:\n",
    "      self.trackers[m[1]].update(dets[m[0], :])\n",
    "\n",
    "    # create and initialise new trackers for unmatched detections\n",
    "    for i in unmatched_dets:\n",
    "        trk = KalmanBoxTracker(dets[i,:])\n",
    "        self.trackers.append(trk)\n",
    "    i = len(self.trackers)\n",
    "    for trk in reversed(self.trackers):\n",
    "        d = trk.get_state()[0]\n",
    "        if (trk.time_since_update < 1) and (trk.hit_streak >= self.min_hits or self.frame_count <= self.min_hits):\n",
    "          ret.append(np.concatenate((d,[trk.id+1])).reshape(1,-1)) # +1 as MOT benchmark requires positive\n",
    "        i -= 1\n",
    "        # remove dead tracklet\n",
    "        if(trk.time_since_update > self.max_age):\n",
    "          self.trackers.pop(i)\n",
    "    if(len(ret)>0):\n",
    "      return np.concatenate(ret)\n",
    "    return np.empty((0,5))\n",
    "\n",
    "def parse_args():\n",
    "    \"\"\"Parse input arguments.\"\"\"\n",
    "    parser = argparse.ArgumentParser(description='SORT demo')\n",
    "    parser.add_argument('--display', dest='display', help='Display online tracker output (slow) [False]',action='store_true')\n",
    "    parser.add_argument(\"--seq_path\", help=\"Path to detections.\", type=str, default='data')\n",
    "    parser.add_argument(\"--phase\", help=\"Subdirectory in seq_path.\", type=str, default='train')\n",
    "    parser.add_argument(\"--max_age\", \n",
    "                        help=\"Maximum number of frames to keep alive a track without associated detections.\", \n",
    "                        type=int, default=1)\n",
    "    parser.add_argument(\"--min_hits\", \n",
    "                        help=\"Minimum number of associated detections before track is initialised.\", \n",
    "                        type=int, default=3)\n",
    "    parser.add_argument(\"--iou_threshold\", help=\"Minimum IOU for match.\", type=float, default=0.3)\n",
    "    args = parser.parse_args()\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
      "\n",
      "0: 384x640 3 persons, 4 cars, 1 bus, 1 truck, 773.0ms\n",
      "Speed: 19.4ms preprocess, 773.0ms inference, 11.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 3870 milliseconds\n",
      "\n",
      "0: 384x640 3 persons, 4 cars, 1 motorcycle, 1 bus, 1 truck, 745.6ms\n",
      "Speed: 2.3ms preprocess, 745.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 888 milliseconds\n",
      "\n",
      "0: 384x640 2 persons, 4 cars, 3 motorcycles, 1 bus, 1 truck, 747.1ms\n",
      "Speed: 2.0ms preprocess, 747.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 827 milliseconds\n",
      "\n",
      "0: 384x640 2 persons, 1 bicycle, 4 cars, 1 motorcycle, 1 bus, 1 truck, 721.1ms\n",
      "Speed: 1.1ms preprocess, 721.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 797 milliseconds\n",
      "\n",
      "0: 384x640 2 persons, 2 bicycles, 3 cars, 3 motorcycles, 1 bus, 1 truck, 713.6ms\n",
      "Speed: 1.0ms preprocess, 713.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 783 milliseconds\n",
      "\n",
      "0: 384x640 2 persons, 2 bicycles, 3 cars, 3 motorcycles, 1 bus, 1 truck, 733.7ms\n",
      "Speed: 2.0ms preprocess, 733.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 921 milliseconds\n",
      "\n",
      "0: 384x640 1 person, 1 bicycle, 3 cars, 2 motorcycles, 1 bus, 1 truck, 729.4ms\n",
      "Speed: 1.5ms preprocess, 729.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 800 milliseconds\n",
      "\n",
      "0: 384x640 2 persons, 1 bicycle, 3 cars, 2 motorcycles, 1 bus, 1 truck, 739.2ms\n",
      "Speed: 1.4ms preprocess, 739.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 846 milliseconds\n",
      "\n",
      "0: 384x640 2 persons, 1 bicycle, 3 cars, 2 motorcycles, 1 bus, 1 truck, 740.7ms\n",
      "Speed: 1.6ms preprocess, 740.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 844 milliseconds\n",
      "\n",
      "0: 384x640 1 person, 1 bicycle, 3 cars, 1 bus, 1 truck, 753.3ms\n",
      "Speed: 1.2ms preprocess, 753.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 858 milliseconds\n",
      "\n",
      "0: 384x640 2 persons, 1 bicycle, 3 cars, 1 bus, 1 truck, 714.6ms\n",
      "Speed: 1.4ms preprocess, 714.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 812 milliseconds\n",
      "\n",
      "0: 384x640 2 persons, 1 bicycle, 3 cars, 1 bus, 1 truck, 688.5ms\n",
      "Speed: 2.1ms preprocess, 688.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 757 milliseconds\n",
      "\n",
      "0: 384x640 2 persons, 1 bicycle, 3 cars, 1 motorcycle, 1 bus, 1 truck, 724.8ms\n",
      "Speed: 1.0ms preprocess, 724.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 793 milliseconds\n",
      "\n",
      "0: 384x640 1 person, 1 bicycle, 3 cars, 1 bus, 1 truck, 726.9ms\n",
      "Speed: 1.0ms preprocess, 726.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 794 milliseconds\n",
      "\n",
      "0: 384x640 2 persons, 1 bicycle, 3 cars, 1 bus, 1 truck, 733.4ms\n",
      "Speed: 1.0ms preprocess, 733.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 802 milliseconds\n",
      "\n",
      "0: 384x640 3 persons, 1 bicycle, 3 cars, 1 bus, 1 truck, 721.0ms\n",
      "Speed: 2.9ms preprocess, 721.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 791 milliseconds\n",
      "\n",
      "0: 384x640 2 persons, 2 bicycles, 3 cars, 1 bus, 1 truck, 723.4ms\n",
      "Speed: 0.5ms preprocess, 723.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 792 milliseconds\n",
      "\n",
      "0: 384x640 2 persons, 1 bicycle, 3 cars, 1 bus, 1 truck, 795.9ms\n",
      "Speed: 1.0ms preprocess, 795.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 866 milliseconds\n",
      "\n",
      "0: 384x640 3 persons, 1 bicycle, 3 cars, 2 buss, 1 truck, 716.7ms\n",
      "Speed: 1.8ms preprocess, 716.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 786 milliseconds\n",
      "\n",
      "0: 384x640 3 persons, 1 bicycle, 4 cars, 2 buss, 1 truck, 711.4ms\n",
      "Speed: 2.5ms preprocess, 711.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 779 milliseconds\n",
      "\n",
      "0: 384x640 4 persons, 1 bicycle, 4 cars, 1 bus, 1 truck, 723.4ms\n",
      "Speed: 1.0ms preprocess, 723.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 789 milliseconds\n",
      "\n",
      "0: 384x640 3 persons, 1 bicycle, 4 cars, 1 bus, 1 truck, 735.6ms\n",
      "Speed: 1.0ms preprocess, 735.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 805 milliseconds\n",
      "\n",
      "0: 384x640 2 persons, 1 bicycle, 4 cars, 1 bus, 1 truck, 727.9ms\n",
      "Speed: 1.0ms preprocess, 727.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 793 milliseconds\n",
      "\n",
      "0: 384x640 4 persons, 1 bicycle, 5 cars, 1 bus, 1 truck, 732.6ms\n",
      "Speed: 1.1ms preprocess, 732.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 801 milliseconds\n",
      "\n",
      "0: 384x640 4 persons, 1 bicycle, 4 cars, 1 bus, 1 truck, 714.7ms\n",
      "Speed: 1.5ms preprocess, 714.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 787 milliseconds\n",
      "\n",
      "0: 384x640 4 persons, 1 bicycle, 4 cars, 1 bus, 1 truck, 833.4ms\n",
      "Speed: 1.0ms preprocess, 833.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 933 milliseconds\n",
      "\n",
      "0: 384x640 3 persons, 1 bicycle, 5 cars, 1 bus, 1 truck, 777.5ms\n",
      "Speed: 2.4ms preprocess, 777.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 852 milliseconds\n",
      "\n",
      "0: 384x640 4 persons, 1 bicycle, 6 cars, 1 bus, 1 truck, 718.5ms\n",
      "Speed: 2.2ms preprocess, 718.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 800 milliseconds\n",
      "\n",
      "0: 384x640 4 persons, 1 bicycle, 5 cars, 1 bus, 1 truck, 786.3ms\n",
      "Speed: 2.0ms preprocess, 786.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 861 milliseconds\n",
      "\n",
      "0: 384x640 4 persons, 1 bicycle, 6 cars, 1 bus, 1 truck, 747.5ms\n",
      "Speed: 2.3ms preprocess, 747.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 822 milliseconds\n",
      "\n",
      "0: 384x640 5 persons, 1 bicycle, 4 cars, 1 bus, 1 truck, 724.4ms\n",
      "Speed: 2.4ms preprocess, 724.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 795 milliseconds\n",
      "\n",
      "0: 384x640 3 persons, 1 bicycle, 6 cars, 1 bus, 1 truck, 737.8ms\n",
      "Speed: 2.1ms preprocess, 737.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 811 milliseconds\n",
      "\n",
      "0: 384x640 2 persons, 1 bicycle, 4 cars, 1 motorcycle, 1 bus, 1 truck, 707.1ms\n",
      "Speed: 2.4ms preprocess, 707.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 779 milliseconds\n",
      "\n",
      "0: 384x640 2 persons, 1 bicycle, 5 cars, 1 motorcycle, 1 bus, 1 truck, 718.7ms\n",
      "Speed: 1.0ms preprocess, 718.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 784 milliseconds\n",
      "\n",
      "0: 384x640 2 persons, 1 bicycle, 6 cars, 2 buss, 1 truck, 724.8ms\n",
      "Speed: 1.0ms preprocess, 724.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 793 milliseconds\n",
      "\n",
      "0: 384x640 2 persons, 1 bicycle, 8 cars, 2 buss, 1 truck, 679.1ms\n",
      "Speed: 1.0ms preprocess, 679.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 746 milliseconds\n",
      "\n",
      "0: 384x640 2 persons, 1 bicycle, 7 cars, 2 buss, 1 truck, 698.1ms\n",
      "Speed: 1.3ms preprocess, 698.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 763 milliseconds\n",
      "\n",
      "0: 384x640 2 persons, 1 bicycle, 7 cars, 2 buss, 1 truck, 728.9ms\n",
      "Speed: 2.0ms preprocess, 728.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 797 milliseconds\n",
      "\n",
      "0: 384x640 2 persons, 7 cars, 1 bus, 1 truck, 720.4ms\n",
      "Speed: 1.1ms preprocess, 720.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 784 milliseconds\n",
      "\n",
      "0: 384x640 2 persons, 1 bicycle, 9 cars, 2 buss, 1 truck, 721.8ms\n",
      "Speed: 1.1ms preprocess, 721.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 787 milliseconds\n",
      "\n",
      "0: 384x640 3 persons, 7 cars, 2 motorcycles, 2 buss, 1 truck, 727.9ms\n",
      "Speed: 2.0ms preprocess, 727.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 804 milliseconds\n",
      "\n",
      "0: 384x640 3 persons, 2 bicycles, 7 cars, 1 motorcycle, 1 bus, 1 truck, 753.4ms\n",
      "Speed: 2.0ms preprocess, 753.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 863 milliseconds\n",
      "\n",
      "0: 384x640 2 persons, 7 cars, 1 motorcycle, 1 bus, 1 truck, 741.9ms\n",
      "Speed: 1.3ms preprocess, 741.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 845 milliseconds\n",
      "\n",
      "0: 384x640 2 persons, 6 cars, 2 motorcycles, 1 bus, 1 truck, 812.9ms\n",
      "Speed: 2.0ms preprocess, 812.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 934 milliseconds\n",
      "\n",
      "0: 384x640 5 persons, 6 cars, 3 motorcycles, 1 bus, 1 truck, 817.8ms\n",
      "Speed: 2.0ms preprocess, 817.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 891 milliseconds\n",
      "\n",
      "0: 384x640 5 persons, 5 cars, 3 motorcycles, 1 bus, 1 truck, 804.3ms\n",
      "Speed: 2.8ms preprocess, 804.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 877 milliseconds\n",
      "\n",
      "0: 384x640 4 persons, 5 cars, 3 motorcycles, 1 bus, 833.5ms\n",
      "Speed: 2.0ms preprocess, 833.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 912 milliseconds\n",
      "\n",
      "0: 384x640 5 persons, 4 cars, 3 motorcycles, 1 bus, 1 truck, 847.4ms\n",
      "Speed: 2.5ms preprocess, 847.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 928 milliseconds\n",
      "\n",
      "0: 384x640 3 persons, 5 cars, 2 motorcycles, 1 bus, 826.3ms\n",
      "Speed: 1.5ms preprocess, 826.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 913 milliseconds\n",
      "\n",
      "0: 384x640 4 persons, 4 cars, 3 motorcycles, 1 bus, 842.4ms\n",
      "Speed: 1.3ms preprocess, 842.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 962 milliseconds\n",
      "\n",
      "0: 384x640 5 persons, 4 cars, 4 motorcycles, 1 bus, 804.2ms\n",
      "Speed: 2.6ms preprocess, 804.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 914 milliseconds\n",
      "\n",
      "0: 384x640 5 persons, 5 cars, 4 motorcycles, 1 bus, 1 truck, 808.2ms\n",
      "Speed: 1.0ms preprocess, 808.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 922 milliseconds\n",
      "\n",
      "0: 384x640 6 persons, 5 cars, 5 motorcycles, 1 bus, 1 truck, 789.8ms\n",
      "Speed: 2.5ms preprocess, 789.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 892 milliseconds\n",
      "\n",
      "0: 384x640 4 persons, 5 cars, 6 motorcycles, 1 bus, 1 truck, 744.6ms\n",
      "Speed: 1.0ms preprocess, 744.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 850 milliseconds\n",
      "\n",
      "0: 384x640 4 persons, 5 cars, 4 motorcycles, 1 bus, 736.0ms\n",
      "Speed: 1.5ms preprocess, 736.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 839 milliseconds\n",
      "\n",
      "0: 384x640 6 persons, 7 cars, 3 motorcycles, 1 bus, 1 truck, 734.5ms\n",
      "Speed: 2.0ms preprocess, 734.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 801 milliseconds\n",
      "\n",
      "0: 384x640 4 persons, 7 cars, 3 motorcycles, 1 bus, 711.9ms\n",
      "Speed: 1.5ms preprocess, 711.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 783 milliseconds\n",
      "\n",
      "0: 384x640 4 persons, 8 cars, 4 motorcycles, 1 bus, 778.1ms\n",
      "Speed: 1.2ms preprocess, 778.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 877 milliseconds\n",
      "\n",
      "0: 384x640 5 persons, 7 cars, 3 motorcycles, 1 bus, 739.2ms\n",
      "Speed: 2.1ms preprocess, 739.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 837 milliseconds\n",
      "\n",
      "0: 384x640 4 persons, 7 cars, 3 motorcycles, 1 bus, 720.0ms\n",
      "Speed: 2.3ms preprocess, 720.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 789 milliseconds\n",
      "\n",
      "0: 384x640 3 persons, 7 cars, 4 motorcycles, 1 bus, 707.3ms\n",
      "Speed: 1.0ms preprocess, 707.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 778 milliseconds\n",
      "\n",
      "0: 384x640 2 persons, 8 cars, 2 motorcycles, 1 bus, 719.4ms\n",
      "Speed: 1.0ms preprocess, 719.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 793 milliseconds\n",
      "\n",
      "0: 384x640 2 persons, 8 cars, 4 motorcycles, 1 bus, 729.4ms\n",
      "Speed: 2.0ms preprocess, 729.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 798 milliseconds\n",
      "\n",
      "0: 384x640 1 person, 6 cars, 4 motorcycles, 1 bus, 722.0ms\n",
      "Speed: 1.0ms preprocess, 722.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 786 milliseconds\n",
      "\n",
      "0: 384x640 4 persons, 6 cars, 5 motorcycles, 1 bus, 701.7ms\n",
      "Speed: 1.0ms preprocess, 701.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 770 milliseconds\n",
      "\n",
      "0: 384x640 4 persons, 6 cars, 6 motorcycles, 1 bus, 721.8ms\n",
      "Speed: 2.0ms preprocess, 721.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 805 milliseconds\n",
      "\n",
      "0: 384x640 5 persons, 5 cars, 5 motorcycles, 2 buss, 791.8ms\n",
      "Speed: 2.9ms preprocess, 791.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 873 milliseconds\n",
      "\n",
      "0: 384x640 7 persons, 5 cars, 5 motorcycles, 1 bus, 770.1ms\n",
      "Speed: 2.0ms preprocess, 770.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 849 milliseconds\n",
      "\n",
      "0: 384x640 5 persons, 7 cars, 6 motorcycles, 1 bus, 748.0ms\n",
      "Speed: 2.0ms preprocess, 748.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 827 milliseconds\n",
      "\n",
      "0: 384x640 6 persons, 7 cars, 4 motorcycles, 1 bus, 783.0ms\n",
      "Speed: 2.2ms preprocess, 783.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 895 milliseconds\n",
      "\n",
      "0: 384x640 6 persons, 6 cars, 4 motorcycles, 1 bus, 763.7ms\n",
      "Speed: 1.4ms preprocess, 763.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 961 milliseconds\n",
      "\n",
      "0: 384x640 5 persons, 7 cars, 3 motorcycles, 1 bus, 734.6ms\n",
      "Speed: 2.2ms preprocess, 734.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 814 milliseconds\n",
      "\n",
      "0: 384x640 4 persons, 8 cars, 3 motorcycles, 1 bus, 737.4ms\n",
      "Speed: 12.9ms preprocess, 737.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 863 milliseconds\n",
      "\n",
      "0: 384x640 4 persons, 8 cars, 3 motorcycles, 1 bus, 723.4ms\n",
      "Speed: 1.0ms preprocess, 723.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 795 milliseconds\n",
      "\n",
      "0: 384x640 5 persons, 8 cars, 4 motorcycles, 1 bus, 737.0ms\n",
      "Speed: 2.0ms preprocess, 737.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 812 milliseconds\n",
      "\n",
      "0: 384x640 5 persons, 7 cars, 5 motorcycles, 1 bus, 722.3ms\n",
      "Speed: 2.2ms preprocess, 722.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 792 milliseconds\n",
      "\n",
      "0: 384x640 4 persons, 8 cars, 3 motorcycles, 1 bus, 755.3ms\n",
      "Speed: 2.0ms preprocess, 755.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 861 milliseconds\n",
      "\n",
      "0: 384x640 6 persons, 8 cars, 5 motorcycles, 1 bus, 743.7ms\n",
      "Speed: 1.0ms preprocess, 743.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 817 milliseconds\n",
      "\n",
      "0: 384x640 5 persons, 8 cars, 5 motorcycles, 1 bus, 742.3ms\n",
      "Speed: 2.0ms preprocess, 742.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 826 milliseconds\n",
      "\n",
      "0: 384x640 6 persons, 8 cars, 5 motorcycles, 1 bus, 783.2ms\n",
      "Speed: 1.0ms preprocess, 783.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 865 milliseconds\n",
      "\n",
      "0: 384x640 5 persons, 7 cars, 4 motorcycles, 1 bus, 813.8ms\n",
      "Speed: 2.1ms preprocess, 813.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 899 milliseconds\n",
      "\n",
      "0: 384x640 6 persons, 8 cars, 4 motorcycles, 1 bus, 804.2ms\n",
      "Speed: 2.0ms preprocess, 804.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 885 milliseconds\n",
      "\n",
      "0: 384x640 4 persons, 10 cars, 4 motorcycles, 1 bus, 875.0ms\n",
      "Speed: 2.5ms preprocess, 875.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 952 milliseconds\n",
      "\n",
      "0: 384x640 6 persons, 7 cars, 4 motorcycles, 1 bus, 842.0ms\n",
      "Speed: 2.0ms preprocess, 842.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 918 milliseconds\n",
      "\n",
      "0: 384x640 6 persons, 7 cars, 5 motorcycles, 1 bus, 794.9ms\n",
      "Speed: 1.3ms preprocess, 794.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 871 milliseconds\n",
      "Total Time to process : 74954 milliseconds\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
    "# from google.colab.patches import cv2_imshow\n",
    "\n",
    "# define come constants for later use\n",
    "CONFIDENCE_THRESHOLD = 0.9\n",
    "GREEN = (0, 255, 0)\n",
    "BLUE = (0, 0, 255)\n",
    "RED = (255, 0, 0)\n",
    "MAGENTA = (255, 255, 0)\n",
    "WHITE = (255, 255, 255)\n",
    "\n",
    "# initialize the video capture object\n",
    "video_cap = cv2.VideoCapture(\"./TrafficJunction9.mp4\")\n",
    "\n",
    "# load the pre-trained YOLOv8n model\n",
    "model = YOLO(\"yolov8x.pt\") # Replace with yolov8m.pt (or) yolov8l.pt (or) yolov8x.pt (or) yolov8n.pt as needed\n",
    "tracker = DeepSort(max_age=50)\n",
    "\n",
    "# Get original frame rate and frame count\n",
    "fps = video_cap.get(cv2.CAP_PROP_FPS)\n",
    "frame_count = int(video_cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "# Get the frame width and height from the video\n",
    "frame_width = int(video_cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(video_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "output_frame_count = 0\n",
    "\n",
    "class_names = model.names\n",
    "print(\"class_names:\", class_names)\n",
    "\n",
    "distinct_ids_seen = set()\n",
    "\n",
    "vehicle_class_names = ['car']\n",
    "total_vehicle_count = 0\n",
    "class_labels = []\n",
    "avg_fps = 0\n",
    "N = 0\n",
    "\n",
    "total_start = datetime.datetime.now()\n",
    "while True:\n",
    "  N+=1\n",
    "  # start time to compute the fps\n",
    "  start = datetime.datetime.now()\n",
    "\n",
    "  ret, frame = video_cap.read()\n",
    "\n",
    "  # if there are no more frames to process, break, out of loop\n",
    "  if not ret:\n",
    "    break\n",
    "\n",
    "  \n",
    "  # run the YOLO model on the frame\n",
    "  detections = model(frame)[0]\n",
    "\n",
    "  # initialize the list of bounding boxes and confidences\n",
    "  results = []\n",
    "\n",
    "  ######################################\n",
    "  # DETECTION\n",
    "  ######################################\n",
    "  \n",
    "  # loop over the detections\n",
    "  for data in detections.boxes.data.tolist():\n",
    "    # extract the confidence (i.e, probability) associated\n",
    "    # with the detection\n",
    "\n",
    "    confidence = data[4]\n",
    "\n",
    "    # filter out weak detections by ensuring the\n",
    "    # confidence is greater than the minimum confidence\n",
    "    if float(confidence) < CONFIDENCE_THRESHOLD:\n",
    "      continue\n",
    "    \n",
    "    # if the confidence is greater than the minimum confidence,\n",
    "    # get the bounding box and class id\n",
    "    xmin, ymin, xmax, ymax = int(data[0]), int(data[1]), int(data[2]), int(data[3])\n",
    "    \n",
    "    class_id = int(data[5])\n",
    "    \n",
    "    # Get class name\n",
    "    class_name = class_names[class_id]\n",
    "    \n",
    "    if(class_name in vehicle_class_names):\n",
    "      # add the bounding box (x, y, w, h), confidence and class id to the results list\n",
    "      results.append([[xmin, ymin, xmax - xmin, ymax - ymin], confidence, class_id])\n",
    "      class_labels.append(class_name)\n",
    "    \n",
    "  ######################################\n",
    "  # TRACKING\n",
    "  ######################################\n",
    "\n",
    "  # update the tracker with the new detections\n",
    "  tracks = tracker.update_tracks(results, frame=frame)\n",
    "  # loop over the tracks\n",
    "  for track in tracks:\n",
    "      # if the track is not confirmed, ignore it\n",
    "      if not track.is_confirmed():\n",
    "          continue\n",
    "\n",
    "      # get the track id and the bounding box\n",
    "      track_id = track.track_id\n",
    "      ltrb = track.to_ltrb()\n",
    "\n",
    "      distinct_ids_seen = distinct_ids_seen.union(set([str(track_id)]))  # Update the set of all distinct IDs seen\n",
    "      total_vehicle_count = len(distinct_ids_seen)\n",
    "\n",
    "      xmin, ymin, xmax, ymax = int(ltrb[0]), int(\n",
    "          ltrb[1]), int(ltrb[2]), int(ltrb[3])\n",
    "      # draw the bounding box and the track id\n",
    "      cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), GREEN, 2)\n",
    "      cv2.putText(frame, str(track_id), (xmin + 5, ymin - 8),\n",
    "                  cv2.FONT_HERSHEY_SIMPLEX, 0.5, WHITE, 2)\n",
    "\n",
    "  # end time to compute the fps\n",
    "  end = datetime.datetime.now()\n",
    "\n",
    "  # show the time it took to process 1 frame\n",
    "  total = (end - start).total_seconds()\n",
    "  print(f\"Time to process 1 frame: {total *  1000:.0f} milliseconds\")\n",
    "\n",
    "  # calculate the frame per second and draw it on the frame\n",
    "  fps = f\"FPS: {1/total:.2f}  Vehicle Count: {total_vehicle_count}\"\n",
    "  cv2.putText(frame, fps, (10, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)\n",
    "\n",
    "  # compute average fps\n",
    "  avg_fps = float(avg_fps*(N-1) + (1/total))/float(N) \n",
    "  \n",
    "  # Write frame to output video\n",
    "  output_frame_count+=1\n",
    "\n",
    "  # show the frame to our screen\n",
    "  cv2.imshow(\"Object Tracking YOLO_DeepSORT \", frame)\n",
    "\n",
    "  if cv2.waitKey(1) == ord(\"q\"):\n",
    "    break\n",
    "\n",
    "total_end = datetime.datetime.now()\n",
    "total_time = (total_end - total_start).total_seconds()\n",
    "print(f\"Total Time to process : {total_time *  1000:.0f} milliseconds\")\n",
    "\n",
    "video_cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car', 'car']\n"
     ]
    }
   ],
   "source": [
    "print(class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "0.5407794038183011\n",
      "Total Time to process : 268315014 seconds\n"
     ]
    }
   ],
   "source": [
    "print(total_vehicle_count)\n",
    "print(avg_fps)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
